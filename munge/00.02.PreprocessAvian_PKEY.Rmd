---
title: "Pre-process avian data at the PKEY level"
author: "Nicole Barker"
date: "Last run: Feb 2, 2018"
output: 
  word_document:
    reference_docx: ../styles/ReportFormat_1.docx
---
## Script Abstract

One of a series of scripts that quality-checks, corrects,  pre-processes, and merges the various tables from BAM's Avian Database. Removes duplicates. Performs some initial tests of patterns in avian data by survey method to help decide how to harmonize the data. 

This script deals with SS (site)-level data, and adds in site-level covariates.

**SCRIPT OUTPUTS:**

1. **data.table in RData file xy.ss.covar.RData (see cache folder on Dropbox)**
2. **csv in output folder in repo for sharing with Trish (or others) (see output folder on Dropbox)**
3. **docx file with text and code snippets plus inline output (written directly to my repo, but ignored by Git. I'll need to copy over manually to Dropbox for sharing)**


## Background
On Nov 30, 2017, Trish provided me with the Access Database of BAM's avian data: COFI_BC_NOV30_2017.accdb. I exported the 3 tables based on BAM's standard data format.

**FILES**

1. **BC_COFI_XY.csv**
2. **BC_COFI_PKEY.txt**
3. **BC_COFI_POINTCOUNT.txt**

**OFFSET-REQUIREMENTS**

* To calculate the Solymos et al 2013 style offsets (correcting for survey method, species availability, species perceptability), we need the following location-specific details: 
    * 

This script does the following

* Look for and eliminate duplications
* Correct any errors noticed during pre-processing
* Save a pre-processed table of SS-level data for further processing/use

The BAM Database is hierarchical, with primary keys for each table compounding upon each other in the various tables. 
It's useful to look at a map to understand how the column names correspond to point count survey protocols/sampling design.  Kathy Martin's data represents a good example. 

* _PCODE_: unique code for each project
* _SITE_: Typically a cluster of point count stations
* _STN_: individual point count survey location
* _SS_: compound key comprised of PCODE:SITE:STN
* _ROUND_: If multiple visits to the same location, typically on different days.
* _PKEY_: compound key -->  PCODE:SITE:STN:YY:ROUND
* _METHOD_: The survey method (survey distance, duration); usually but not always consistent within a PCODE.
* _obs_: Identity of the survey observer.

![ ^^^ Image. BBS, Atlas (BCCA), and KMART (Kathy Martin)'s data, as an example of PCODE, SITE, and STN. Different coloured dots are from different projects (PCODEs). Kathy Martin's data (KMART) has clusters of stations in different sites (SITE), which are labelled KNIFEAFF, KNIFE7M, etc. Within (SITE) clusters are individual stations (STN). The combination of PCODE:SITE:STN makes up SS, which is a  unique ID corresponding to a given location indicated by xy coordinates](../images/KathyMartinSITEdemo.jpg)

``` {r setup, echo=F, message=F, warning=F}
require(knitr)
opts_knit$set(root.dir = '..')
```

Source setup script
``` {r, warning=F, message=F}
source("lib/Setup_NB_WorkPC.R")
source("lib/Setup_anyComputer.R")
```

### 2. Sampling Occasions: *BC_COFI_PKEY.txt*
The BAM Database is hierarchical, with primary keys for each table compounding upon each other in the various tables. 
It's useful to look at a map to understand how the column names correspond to point count survey protocols/sampling design.  Kathy Martin's data represents a good example. 

* _PCODE_: unique code for each project
* _SITE_: Typically a cluster of point count stations
* _STN_: individual point count survey location
* _SS_: compound key comprised of PCODE:SITE:STN
* _ROUND_: If multiple visits to the same location, typically on different days.
* _PKEY_: compound key -->  PCODE:SITE:STN:YY:ROUND
* _METHOD_: The survey method (survey distance, duration); usually but not always consistent within a PCODE.
* _obs_: Identity of the survey observer.

![ ^^^ Image. BBS, Atlas (BCCA), and KMART (Kathy Martin)'s data, as an example of PCODE, SITE, and STN. Different coloured dots are from different projects (PCODEs). Kathy Martin's data (KMART) has clusters of stations in different sites (SITE), which are labelled KNIFEAFF, KNIFE7M, etc. Within (SITE) clusters are individual stations (STN). The combination of PCODE:SITE:STN makes up SS, which is a  unique ID corresponding to a given location indicated by xy coordinates](../output/KathyMartinSITEdemo.jpg)

``` {r load.pkey}
pkey <- read.csv("data/BC_COFI_PKEY.txt")
kable(rbind(head(pkey), tail(pkey)), row.names=F)
unique(pkey$METHOD)
```

**Checking for Missing Data**

``` {r}
kable(as.data.frame(do.call(rbind,lapply(pkey, function(x) {sum(is.na(x))}))), caption="Number of missing values per column")
kable(as.data.frame(do.call(rbind,lapply(pkey, function(x) {length(unique(x))}))), caption="Number unique values per column")
nrow(pkey)
length(unique(pkey$PKEY))
```

``` {r}
pkey$StartTime[pkey$StartTime == ""] <- NA #if start time is blank, make "NA"

pkey$Missing_StartTime <- NA
pkey$Missing_StartTime[!is.na(pkey$StartTime)] <- "NOT missing Sampling Date"

pkey$Missing_HR_MIN <- NA
pkey$Missing_HR_MIN[!(is.na(pkey$HR) & is.na(pkey$MIN))] <- "NOT missing Start Time"

pkey$Missing_SamplingDate <- NA
pkey$Missing_SamplingDate[!(is.na(pkey$MM) | is.na(pkey$DD))] <- "NOT missing Sampling Date"
```

**Some Checks**

``` {r}
unique(pkey[pkey$Missing_SamplingDate == "NOT missing Sampling Date",]$DD)
unique(pkey[pkey$Missing_SamplingDate == "NOT missing Sampling Date",]$MM)
```

**ERROR NOTICED** - I'm pretty sure no surveys were done in Nov and Dec, so this probably indicates a switch in MM and DD for some sites. Time to track down which ones 

``` {r}
pkey$MM.old <- pkey$MM
pkey$DD.old <- pkey$DD
pkey <- pkey[order(pkey$YYYY, pkey$SS),]

kable(rbind(head(pkey[pkey$PCODE %in% "GMSMON15", c("PCODE", "SS", "YYYY", "MM", "DD", "MM.old")], 10), tail(pkey[pkey$PCODE %in% "GMSMON15", c("PCODE", "SS", "YYYY", "MM", "DD", "MM.old")], 10)), row.names=F)

pkey$DD[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012"] <- pkey$MM.old[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012"] 

pkey$MM[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012"] <-
  pkey$DD.old[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012"]

kable(rbind(head(pkey[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012",c("PCODE", "SS", "YYYY", "MM", "DD")]),
            tail(pkey[pkey$PCODE %in% "GMSMON15" & pkey$YYYY == "2012",c("PCODE", "SS", "YYYY", "MM", "DD")])), row.names=F)
unique(pkey$MM)
```

Alright, so that fixed the obvious date issues. Let's look at some other potential data problems. 

``` {r}
pkey$DATE <- as.Date(paste(pkey$YYYY, pkey$MM, pkey$DD, sep="/"))
```

**Notes**

* The pkey table has `r nrow(pkey)` rows covering `r length(unique(pkey$SS))` SS from `r length(unique(pkey$SITE))` sites over `r length(unique(pkey$PCODE))` projects. This corresponds to `r length(unique(pkey$PKEY))` unique PKEYS
* The earliest point count was done in `r min(pkey$YYYY)`.
* Sometimes the addition of WSI data added projects we already had from the Atlas. So we need to look for duplicated locations and years to remove those duplicates.
